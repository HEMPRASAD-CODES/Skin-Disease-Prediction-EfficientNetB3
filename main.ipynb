import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import cv2
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.applications import EfficientNetB3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import warnings
warnings.filterwarnings('ignore')
import os
os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'
os.environ['TF_GPU_THREAD_COUNT'] = '2'

np.random.seed(42)
tf.random.set_seed(42)

print("TensorFlow version:", tf.__version__)
print("GPU Available:", tf.config.list_physical_devices('GPU'))

BASE_PATH = '/kaggle/input/ham1000'
IMAGES_PATH_1 = f'{BASE_PATH}/HAM10000_images_part_1'
IMAGES_PATH_2 = f'{BASE_PATH}/HAM10000_images_part_2'
METADATA_PATH = f'{BASE_PATH}/HAM10000_metadata.csv'

print("Loading metadata...")
df = pd.read_csv(METADATA_PATH)
print(f"Dataset shape: {df.shape}")
print("\nFirst few rows:")
print(df.head())

print("\nDataset info:")
print(df.info())

print("\nClass distribution:")
class_counts = df['dx'].value_counts()
print(class_counts)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
class_counts.plot(kind='bar')
plt.title('Class Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

plt.subplot(1, 2, 2)
plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%')
plt.title('Class Distribution (Pie Chart)')
plt.show()

def load_and_preprocess_image(image_id, img_size=224):
    img_path_1 = os.path.join(IMAGES_PATH_1, f'{image_id}.jpg')
    img_path_2 = os.path.join(IMAGES_PATH_2, f'{image_id}.jpg')
    if os.path.exists(img_path_1):
        img_path = img_path_1
    elif os.path.exists(img_path_2):
        img_path = img_path_2
    else:
        return None
    try:
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (img_size, img_size))
        img = img.astype(np.float32) / 255.0
        return img
    except:
        return None

print("Loading and preprocessing images...")
IMG_SIZE = 224
images = []
labels = []
valid_indices = []

for idx, row in df.iterrows():
    img = load_and_preprocess_image(row['image_id'], IMG_SIZE)
    if img is not None:
        images.append(img)
        labels.append(row['dx'])
        valid_indices.append(idx)
    if len(images) % 1000 == 0:
        print(f"Processed {len(images)} images...")

print(f"Successfully loaded {len(images)} images")

X = np.array(images)
y = np.array(labels)
print(f"Images shape: {X.shape}")
print(f"Labels shape: {y.shape}")

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
plt.figure(figsize=(15,5))
for i in range(5):
    plt.subplot(1,5,i+1)
    plt.imshow(X[i])
    plt.title(f"Label: {label_encoder.inverse_transform([y_encoded[i]])[0]}")
    plt.axis('off')
plt.show()
print("Unique encoded labels:", np.unique(y_encoded))
print("First 5 labels (encoded):", y_encoded[:5])
plt.imshow(X[0])
plt.title(f"Label: {y_encoded[0]}")
plt.show()
num_classes = len(label_encoder.classes_)

print(f"Number of classes: {num_classes}")
print("Class mapping:")
for i, class_name in enumerate(label_encoder.classes_):
    print(f"{i}: {class_name}")

plt.figure(figsize=(15, 10))
for i, class_name in enumerate(label_encoder.classes_):
    class_indices = np.where(y == class_name)[0]
    if len(class_indices) > 0:
        img_idx = class_indices[0]
        plt.subplot(2, 4, i+1)
        plt.imshow(X[img_idx])
        plt.title(f'{class_name}\n({len(class_indices)} samples)')
        plt.axis('off')
plt.tight_layout()
plt.show()

print("Splitting data...")
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)
print(f"Training set: {X_train.shape[0]} samples")
print(f"Validation set: {X_val.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")

class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weight_dict = dict(enumerate(class_weights))
print("Class weights:", class_weight_dict)

train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.1,
    shear_range=0.1,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest'
)
val_datagen = ImageDataGenerator()

batch_size = 128
train_generator = val_datagen.flow(
    X_train, y_train,
    batch_size=batch_size,
    shuffle=True
)
val_generator = val_datagen.flow(
    X_val, y_val,
    batch_size=batch_size,
    shuffle=False
)

def create_model(input_shape=(224, 224, 3), num_classes=7):
    base_model = EfficientNetB3(
        weights='imagenet',
        include_top=False,
        input_shape=input_shape
    )
    base_model.trainable = False
    inputs = tf.keras.Input(shape=input_shape)
    x = base_model(inputs, training=False)
    x = layers.Flatten()(x)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(256, activation='relu')(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)
    model = tf.keras.Model(inputs, outputs)
    return model, base_model

from tensorflow.keras.losses import Loss
import tensorflow as tf

class SparseCategoricalFocalLoss(Loss):
    def __init__(self, alpha=0.25, gamma=2.0, from_logits=False, name="sparse_categorical_focal_loss"):
        super().__init__(name=name)
        self.alpha = alpha
        self.gamma = gamma
        self.from_logits = from_logits

    def call(self, y_true, y_pred):
        y_true = tf.cast(y_true, tf.int32)
        y_true_one_hot = tf.one_hot(y_true, depth=tf.shape(y_pred)[-1])
        if self.from_logits:
            y_pred = tf.nn.softmax(y_pred, axis=-1)
        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)
        cross_entropy = -y_true_one_hot * tf.math.log(y_pred)
        loss = self.alpha * tf.pow(1.0 - y_pred, self.gamma) * cross_entropy
        return tf.reduce_sum(loss, axis=-1)

print("Creating model...")
model, base_model = create_model(num_classes=num_classes)
alpha_values = 1.0 / class_weights
focal_loss = SparseCategoricalFocalLoss(
    alpha=alpha_values,
    gamma=2.0,
    from_logits=False
)
model.compile(
    optimizer=optimizers.Adam(learning_rate=0.00001),
    loss=focal_loss,
    metrics=['accuracy'],
    jit_compile=True
)
model.summary()

callbacks = [
    ModelCheckpoint(
        'best_skin_disease_model.h5',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    ),
    EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    )
]

print("Starting Phase 1 training (frozen base model)...")
history_phase1 = model.fit(
    train_generator,
    steps_per_epoch=len(X_train) // batch_size,
    epochs=15,
    validation_data=val_generator,
    validation_steps=len(X_val) // batch_size,
    callbacks=callbacks,
    verbose=1
)

print("Starting Phase 2 training (fine-tuning)...")
base_model.trainable = True
model.compile(
    optimizer=optimizers.Adam(learning_rate=0.0001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy'],
    jit_compile=True
)
history_phase2 = model.fit(
    train_generator,
    steps_per_epoch=len(X_train) // batch_size,
    epochs=25,
    validation_data=val_generator,
    validation_steps=len(X_val) // batch_size,
    callbacks=callbacks,
    verbose=1,
    initial_epoch=len(history_phase1.history['loss'])
)

def plot_training_history(history1, history2):
    acc = history1.history['accuracy'] + history2.history['accuracy']
    val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']
    loss = history1.history['loss'] + history2.history['loss']
    val_loss = history1.history['val_loss'] + history2.history['val_loss']
    epochs = range(1, len(acc) + 1)
    plt.figure(figsize=(15, 5))
    plt.subplot(1, 3, 1)
    plt.plot(epochs, acc, 'b-', label='Training Accuracy')
    plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    plt.subplot(1, 3, 2)
    plt.plot(epochs, loss, 'b-', label='Training Loss')
    plt.plot(epochs, val_loss, 'r-', label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.subplot(1, 3, 3)
    if 'lr' in history1.history:
        lr = history1.history['lr'] + history2.history['lr']
        plt.plot(epochs, lr, 'g-', label='Learning Rate')
        plt.title('Learning Rate')
        plt.xlabel('Epoch')
        plt.ylabel('Learning Rate')
        plt.yscale('log')
        plt.legend()
        plt.grid(True)
    plt.tight_layout()
    plt.show()

plot_training_history(history_phase1, history_phase2)

print("Evaluating model on test set...")
test_predictions = model.predict(X_test, batch_size=batch_size)
test_pred_classes = np.argmax(test_predictions, axis=1)
print("\nClassification Report:")
print(classification_report(
    y_test, 
    test_pred_classes, 
    target_names=label_encoder.classes_
))
cm = confusion_matrix(y_test, test_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(
    cm, 
    annot=True, 
    fmt='d', 
    cmap='Blues',
    xticklabels=label_encoder.classes_,
    yticklabels=label_encoder.classes_
)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()
test_accuracy = np.mean(test_pred_classes == y_test)
print(f"\nTest Accuracy: {test_accuracy:.4f}")

print("Saving model and artifacts...")
model.save('skin_disease_detector_final.h5')
print("Model saved as 'skin_disease_detector_final.h5'")
import pickle
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(label_encoder, f)
print("Label encoder saved as 'label_encoder.pkl'")
model_config = {
    'input_shape': (IMG_SIZE, IMG_SIZE, 3),
    'num_classes': num_classes,
    'class_names': label_encoder.classes_.tolist(),
    'img_size': IMG_SIZE,
    'test_accuracy': float(test_accuracy)
}
import json
with open('model_config.json', 'w') as f:
    json.dump(model_config, f, indent=2)
print("Model configuration saved as 'model_config.json'")

def predict_skin_disease(image_path, model, label_encoder, img_size=224):
    try:
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (img_size, img_size))
        img = img.astype(np.float32) / 255.0
        img = np.expand_dims(img, axis=0)
        predictions = model.predict(img)
        predicted_class_idx = np.argmax(predictions[0])
        confidence = predictions[0][predicted_class_idx]
        predicted_class = label_encoder.classes_[predicted_class_idx]
        class_probabilities = {}
        for i, class_name in enumerate(label_encoder.classes_):
            class_probabilities[class_name] = float(predictions[0][i])
        return {
            'predicted_class': predicted_class,
            'confidence': float(confidence),
            'all_probabilities': class_probabilities
        }
    except Exception as e:
        return {'error': str(e)}

if len(X_test) > 0:
    print("\nTesting prediction function...")
    test_img = (X_test[0] * 255).astype(np.uint8)
    cv2.imwrite('temp_test_image.jpg', cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR))
    result = predict_skin_disease('temp_test_image.jpg', model, label_encoder)
    print("Sample prediction result:", result)
    os.remove('temp_test_image.jpg')

print("\n" + "="*50)
print("TRAINING COMPLETED SUCCESSFULLY!")
print("="*50)
print(f"Final Test Accuracy: {test_accuracy:.4f}")
print(f"Model saved as: skin_disease_detector_final.h5")
print(f"Label encoder saved as: label_encoder.pkl")
print(f"Configuration saved as: model_config.json")
print("="*50)
print("\nFINAL RESULTS SUMMARY:")
print(f"• Dataset: HAM10000 ({len(images)} images)")
print(f"• Classes: {num_classes}")
print(f"• Architecture: EfficientNetB3 + Custom Head")
print(f"• Test Accuracy: {test_accuracy:.4f}")
print(f"• Model Size: {os.path.getsize('skin_disease_detector_final.h5') / (1024*1024):.1f} MB")
